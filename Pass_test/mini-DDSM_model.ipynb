{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 00:15:01.454536: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-17 00:15:02.429976: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jj/miniconda3/envs/wsl_tf/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/include:/usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64::/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-01-17 00:15:02.430080: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jj/miniconda3/envs/wsl_tf/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/include:/usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64::/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-01-17 00:15:02.430086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-17 00:15:03.468491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 00:15:03.495625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 00:15:03.495740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.image import resize_with_pad, grayscale_to_rgb\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout, Conv2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "PATH = \"/mnt/d/Datasets/mini-DDSM/\"\n",
    "imgPATH = PATH + \"MINI-DDSM-Complete-PNG-16/\"\n",
    "roi_path = PATH + \"ROI/\"\n",
    "save_dir = \"/home/jj/FYP/Pass_test/\"\n",
    "image_size = 224\n",
    "batch_size = 8\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "os.environ['TF_ENABLE_GPU_GARBAGE_COLLECTION'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2830 files belonging to 2 classes.\n",
      "Using 2264 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 00:15:07.606399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-17 00:15:07.607697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 00:15:07.607740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 00:15:07.607755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 00:15:08.392380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 00:15:08.392451: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 00:15:08.392456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-01-17 00:15:08.392478: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 00:15:08.392883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5389 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  roi_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(image_size, image_size),\n",
    "  batch_size=batch_size)\n",
    "  \n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  roi_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(image_size, image_size),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "  # # Resize and rescale all datasets.\n",
    "  \n",
    "  data_augmentation = tf.keras.Sequential([\n",
    "  # Input(shape=(None,None,3)),\n",
    "  tf.keras.layers.RandomFlip('horizontal_and_vertical'),\n",
    "  tf.keras.layers.RandomRotation((0,0.3),fill_mode=\"constant\"),\n",
    "  # tf.keras.layers.RandomZoom(height_factor=(-0.5,0.5),width_factor=(-0.5,0.5),fill_mode=\"constant\"),\n",
    "  # tf.keras.layers.RandomTranslation(height_factor=(-0.25,0.25),width_factor=(-0.25,0.25),fill_mode=\"constant\")\n",
    "  ])\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(1000)\n",
    "\n",
    "  # Batch all datasets.\n",
    "  # ds = ds.batch(batch_size)\n",
    "\n",
    "  # Use data augmentation only on the training set.\n",
    "  if augment:\n",
    "    # ds = ds.map(lambda x, y: (resize_and_rescale(x), y), \n",
    "    #           num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x,training=True),y), \n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_aug = prepare(train_ds, shuffle=True, augment=False)\n",
    "val_ds = prepare(val_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training dense layers to categorise output from CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing = tf.keras.applications.inception_v3.preprocess_input\n",
    "# pre_trained = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size,image_size,3))\n",
    "# pre_trained.trainable = False\n",
    "# #Define model architect\n",
    "# tfinput = Input(shape=(image_size,image_size,3) )\n",
    "# pre_process = preprocessing(tfinput)\n",
    "# inceptionv3_model=pre_trained(pre_process,training=False)\n",
    "# flatten = GlobalAveragePooling2D()(inceptionv3_model)\n",
    "# DO1 = Dropout(0.5)(flatten)\n",
    "# Dense1 = Dense(256,activation = 'relu')(DO1)\n",
    "# DO2 = Dropout(0.8)(Dense1)\n",
    "# # DO2 = Dropout(0.8)(flatten)\n",
    "# output = Dense(1, activation=\"sigmoid\")(DO2)\n",
    "# model = Model(tfinput,output)\n",
    "# #Prevent overfitting with early stopping\n",
    "# Earlystop = tf.keras.callbacks.EarlyStopping( monitor='val_accuracy'\n",
    "#                                               ,patience=10\n",
    "#                                               # ,start_from_epoch = 0\n",
    "#                                               # ,baseline = 0.7\n",
    "#                                               ,restore_best_weights = True\n",
    "#                                               ,verbose = 1\n",
    "#                                               )\n",
    "# model.compile(\n",
    "#     optimizer= tf.keras.optimizers.Adam(learning_rate = 1e-4),\n",
    "#     loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Training Dense layers to initialise the categoriser before fine tuning the CNN models\n",
    "# total_epochs = 50\n",
    "# history_init = model.fit(train_ds_aug\n",
    "#                     ,epochs=total_epochs\n",
    "#                     ,validation_data=val_ds\n",
    "#                     ,callbacks = Earlystop\n",
    "#                     )\n",
    "# # model.save(save_dir + \"inceptionv3\")\n",
    "# plt.plot(history_init.history['loss'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and save categoriser(Dense layers)\n",
    "\n",
    "Load into model to continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inceptionv3_categoriser_input = model.get_layer(name = \"dropout\").get_output_at(0)\n",
    "# inceptionv3_categoriser_output = model.get_layer(name = \"dense_1\").get_output_at(0)\n",
    "# inceptionv3_categoriser = Model(inceptionv3_categoriser_input, inceptionv3_categoriser_output)\n",
    "# # inceptionv3_categoriser.summary()\n",
    "# inceptionv3_categoriser.save(\"/home/jj/FYP/Pass_test/incpetionv3_categoriser\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load categoriser into model for fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " sequential_4 (Sequential)   (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " tf.math.truediv_2 (TFOpLamb  (None, 224, 224, 3)      0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " tf.math.subtract_2 (TFOpLam  (None, 224, 224, 3)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " model_5 (Functional)        (None, 1)                 524801    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,327,585\n",
      "Trainable params: 11,639,681\n",
      "Non-trainable params: 10,687,904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal_and_vertical'),\n",
    "  tf.keras.layers.RandomRotation((0,0.3),fill_mode=\"constant\"),\n",
    "  tf.keras.layers.RandomZoom(height_factor=(-0.5,0.5),width_factor=(-0.5,0.5),fill_mode=\"constant\"),\n",
    "  tf.keras.layers.RandomTranslation(height_factor=(-0.25,0.25),width_factor=(-0.25,0.25),fill_mode=\"constant\")\n",
    "  ])\n",
    "preprocessing = tf.keras.applications.inception_v3.preprocess_input\n",
    "pre_trained = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size,image_size,3))\n",
    "pre_trained.trainable = True\n",
    "for layer in pre_trained.layers[:-64]:\n",
    "    layer.trainable = False\n",
    "tfinput = Input(shape=(image_size,image_size,3) )\n",
    "data_augment = data_augmentation(tfinput)\n",
    "pre_process = preprocessing(data_augment)\n",
    "inceptionv3_model=pre_trained(pre_process,training=False)\n",
    "categoriser = load_model(\"/home/jj/FYP/Pass_test/incpetionv3_categoriser\")\n",
    "pooling = GlobalAveragePooling2D()(inceptionv3_model)\n",
    "output = categoriser(pooling,training=True)\n",
    "model = Model(tfinput,output)\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate = 1e-6),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "# Earlystop = tf.keras.callbacks.EarlyStopping( monitor='val_accuracy'\n",
    "#                                               ,patience=10\n",
    "#                                               # ,start_from_epoch = 20\n",
    "#                                               # ,baseline = 0.7\n",
    "#                                               ,restore_best_weights = True\n",
    "#                                               ,verbose = 1\n",
    "#                                               )\n",
    "model.summary()\n",
    "\n",
    "Checkpoint = tf.keras.callbacks.ModelCheckpoint(  \n",
    "                                                  filepath=\"/home/jj/FYP/Pass_test/inceptionv3_best_model\"\n",
    "                                                , save_weights_only=True\n",
    "                                                , monitor='val_loss'\n",
    "                                                , mode = 'min'\n",
    "                                                , save_best_only=True\n",
    "                                                , verbose=1\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.6700 - accuracy: 0.5760"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m total_epochs \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m----> 2\u001b[0m history_inceptionv3_init \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_ds_aug\n\u001b[1;32m      3\u001b[0m                     ,epochs\u001b[39m=\u001b[39;49mtotal_epochs\n\u001b[1;32m      4\u001b[0m                     ,validation_data\u001b[39m=\u001b[39;49mval_ds\n\u001b[1;32m      5\u001b[0m                     ,callbacks \u001b[39m=\u001b[39;49m [DWELL(model,\u001b[39mFalse\u001b[39;49;00m,\u001b[39m.5\u001b[39;49m,\u001b[39mTrue\u001b[39;49;00m)]\n\u001b[1;32m      6\u001b[0m                     )\n",
      "File \u001b[0;32m~/miniconda3/envs/wsl_tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m, in \u001b[0;36mDWELL.on_epoch_end\u001b[0;34m(self, epoch, factor, logs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_epoch_end\u001b[39m(\u001b[39mself\u001b[39m, epoch, factor, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# method runs on the end of each epoch\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     lr\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mget_value(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mlr)) \u001b[39m# get the current learning rate        \u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     vloss\u001b[39m=\u001b[39mlogs\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# get the validation loss for this epoch \u001b[39;00m\n\u001b[1;32m     14\u001b[0m     acc\u001b[39m=\u001b[39mlogs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmonitor_acc\u001b[39m==\u001b[39m\u001b[39mFalse\u001b[39;00m: \u001b[39m# monitor validation loss\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "total_epochs = 100\n",
    "history_inceptionv3_init = model.fit(train_ds_aug\n",
    "                    ,epochs=total_epochs\n",
    "                    ,validation_data=val_ds\n",
    "                    ,callbacks = [Checkpoint]\n",
    "                    )\n",
    "# if(history_inceptionv3_init.history['accuracy'])\n",
    "model.save(save_dir + \"Inceptionv3_TL_FT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.6159 - accuracy: 0.6533 - val_loss: 0.6159 - val_accuracy: 0.6678\n",
      "Epoch 18/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.6161 - accuracy: 0.6568 - val_loss: 0.6213 - val_accuracy: 0.6802\n",
      "Epoch 19/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.6048 - accuracy: 0.6696 - val_loss: 0.6392 - val_accuracy: 0.6608\n",
      "Epoch 20/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.6080 - accuracy: 0.6599 - val_loss: 0.6215 - val_accuracy: 0.6820\n",
      "Epoch 21/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5997 - accuracy: 0.6789 - val_loss: 0.6221 - val_accuracy: 0.6784\n",
      "Epoch 22/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5981 - accuracy: 0.6625 - val_loss: 0.6353 - val_accuracy: 0.6731\n",
      "Epoch 23/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5954 - accuracy: 0.6670 - val_loss: 0.6113 - val_accuracy: 0.6696\n",
      "Epoch 24/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.6054 - accuracy: 0.6683 - val_loss: 0.6448 - val_accuracy: 0.6767\n",
      "Epoch 25/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5918 - accuracy: 0.6776 - val_loss: 0.6298 - val_accuracy: 0.6731\n",
      "Epoch 26/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5963 - accuracy: 0.6749 - val_loss: 0.6314 - val_accuracy: 0.6625\n",
      "Epoch 27/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5882 - accuracy: 0.6851 - val_loss: 0.6346 - val_accuracy: 0.6873\n",
      "Epoch 28/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5980 - accuracy: 0.6776 - val_loss: 0.6225 - val_accuracy: 0.6802\n",
      "Epoch 29/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5830 - accuracy: 0.6895 - val_loss: 0.6175 - val_accuracy: 0.6678\n",
      "Epoch 30/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5897 - accuracy: 0.6851 - val_loss: 0.6185 - val_accuracy: 0.6767\n",
      "Epoch 31/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5761 - accuracy: 0.7001 - val_loss: 0.6290 - val_accuracy: 0.6784\n",
      "Epoch 32/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5807 - accuracy: 0.6864 - val_loss: 0.6114 - val_accuracy: 0.6784\n",
      "Epoch 33/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5787 - accuracy: 0.6899 - val_loss: 0.6212 - val_accuracy: 0.6767\n",
      "Epoch 34/66\n",
      "283/283 [==============================] - 16s 47ms/step - loss: 0.5828 - accuracy: 0.6948 - val_loss: 0.6270 - val_accuracy: 0.6784\n",
      "Epoch 35/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5786 - accuracy: 0.6873 - val_loss: 0.6106 - val_accuracy: 0.6837\n",
      "Epoch 36/66\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5756 - accuracy: 0.6890 - val_loss: 0.5999 - val_accuracy: 0.6749\n",
      "Epoch 37/66\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.5805 - accuracy: 0.6939Restoring model weights from the end of the best epoch: 27.\n",
      "283/283 [==============================] - 16s 49ms/step - loss: 0.5805 - accuracy: 0.6939 - val_loss: 0.6018 - val_accuracy: 0.6820\n",
      "Epoch 37: early stopping\n",
      "Epoch 38/87\n",
      "283/283 [==============================] - 16s 49ms/step - loss: 0.5871 - accuracy: 0.6824 - val_loss: 0.6222 - val_accuracy: 0.6820\n",
      "Epoch 39/87\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5927 - accuracy: 0.6815 - val_loss: 0.6186 - val_accuracy: 0.6678\n",
      "Epoch 40/87\n",
      "283/283 [==============================] - 16s 49ms/step - loss: 0.5809 - accuracy: 0.6886 - val_loss: 0.6058 - val_accuracy: 0.6908\n",
      "Epoch 41/87\n",
      "283/283 [==============================] - 16s 49ms/step - loss: 0.5796 - accuracy: 0.6877 - val_loss: 0.6338 - val_accuracy: 0.6873\n",
      "Epoch 42/87\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5805 - accuracy: 0.7019 - val_loss: 0.6133 - val_accuracy: 0.6873\n",
      "Epoch 43/87\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5767 - accuracy: 0.6935 - val_loss: 0.6215 - val_accuracy: 0.6855\n",
      "Epoch 44/87\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5658 - accuracy: 0.7001 - val_loss: 0.6285 - val_accuracy: 0.6873\n",
      "Epoch 45/87\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5766 - accuracy: 0.6890 - val_loss: 0.6141 - val_accuracy: 0.6855\n",
      "Epoch 46/87\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5775 - accuracy: 0.6939 - val_loss: 0.5985 - val_accuracy: 0.6714\n",
      "Epoch 47/87\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5706 - accuracy: 0.6988 - val_loss: 0.6009 - val_accuracy: 0.6873\n",
      "Epoch 48/87\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5750 - accuracy: 0.6957 - val_loss: 0.5955 - val_accuracy: 0.6784\n",
      "Epoch 49/87\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5700 - accuracy: 0.7027 - val_loss: 0.6021 - val_accuracy: 0.6820\n",
      "Epoch 50/87\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.7041Restoring model weights from the end of the best epoch: 40.\n",
      "283/283 [==============================] - 16s 49ms/step - loss: 0.5688 - accuracy: 0.7041 - val_loss: 0.6085 - val_accuracy: 0.6837\n",
      "Epoch 50: early stopping\n",
      "Epoch 51/100\n",
      "283/283 [==============================] - 17s 49ms/step - loss: 0.5855 - accuracy: 0.6860 - val_loss: 0.6075 - val_accuracy: 0.6996\n",
      "Epoch 52/100\n",
      "283/283 [==============================] - 16s 49ms/step - loss: 0.5891 - accuracy: 0.6895 - val_loss: 0.6189 - val_accuracy: 0.6837\n",
      "Epoch 53/100\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5771 - accuracy: 0.6957 - val_loss: 0.6306 - val_accuracy: 0.6802\n",
      "Epoch 54/100\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5715 - accuracy: 0.7023 - val_loss: 0.6425 - val_accuracy: 0.6837\n",
      "Epoch 55/100\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5761 - accuracy: 0.6921 - val_loss: 0.6154 - val_accuracy: 0.6661\n",
      "Epoch 56/100\n",
      "283/283 [==============================] - 16s 49ms/step - loss: 0.5727 - accuracy: 0.6899 - val_loss: 0.6075 - val_accuracy: 0.6784\n",
      "Epoch 57/100\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5753 - accuracy: 0.6917 - val_loss: 0.6117 - val_accuracy: 0.6855\n",
      "Epoch 58/100\n",
      "283/283 [==============================] - 16s 49ms/step - loss: 0.5681 - accuracy: 0.7080 - val_loss: 0.6164 - val_accuracy: 0.6855\n",
      "Epoch 59/100\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5764 - accuracy: 0.6868 - val_loss: 0.6100 - val_accuracy: 0.6820\n",
      "Epoch 60/100\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5751 - accuracy: 0.6961 - val_loss: 0.6081 - val_accuracy: 0.6855\n",
      "Epoch 61/100\n",
      "282/283 [============================>.] - ETA: 0s - loss: 0.5672 - accuracy: 0.7008Restoring model weights from the end of the best epoch: 51.\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5676 - accuracy: 0.7001 - val_loss: 0.6363 - val_accuracy: 0.6802\n",
      "Epoch 61: early stopping\n",
      "Epoch 62/111\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5874 - accuracy: 0.6948 - val_loss: 0.6145 - val_accuracy: 0.6678\n",
      "Epoch 63/111\n",
      "283/283 [==============================] - 16s 49ms/step - loss: 0.5757 - accuracy: 0.7001 - val_loss: 0.6166 - val_accuracy: 0.6873\n",
      "Epoch 64/111\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5832 - accuracy: 0.6868 - val_loss: 0.5949 - val_accuracy: 0.6943\n",
      "Epoch 65/111\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5796 - accuracy: 0.6833 - val_loss: 0.6217 - val_accuracy: 0.6820\n",
      "Epoch 66/111\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5713 - accuracy: 0.6908 - val_loss: 0.6311 - val_accuracy: 0.6749\n",
      "Epoch 67/111\n",
      "283/283 [==============================] - 17s 51ms/step - loss: 0.5753 - accuracy: 0.6961 - val_loss: 0.5970 - val_accuracy: 0.6855\n",
      "Epoch 68/111\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5785 - accuracy: 0.6899 - val_loss: 0.6111 - val_accuracy: 0.6890\n",
      "Epoch 69/111\n",
      "283/283 [==============================] - 16s 48ms/step - loss: 0.5687 - accuracy: 0.7058 - val_loss: 0.6130 - val_accuracy: 0.6731\n",
      "Epoch 70/111\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x=0\n",
    "while history_inceptionv3_init.history['accuracy'][-1]<0.8 and x<5:\n",
    "    start_epoch = history_inceptionv3_init.epoch[-1] + 1\n",
    "    total_epochs = start_epoch+50\n",
    "    history_inceptionv3_init = model.fit(train_ds_aug\n",
    "                    ,epochs=total_epochs\n",
    "                    ,validation_data=val_ds\n",
    "                    ,callbacks = Earlystop\n",
    "                    ,initial_epoch=start_epoch\n",
    "                    )\n",
    "    if history_inceptionv3_init.history['accuracy'][-1] < 0.6:\n",
    "        x=x\n",
    "    else:\n",
    "        x=x+1\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the layers except the last 2 layers\n",
    "tf.keras.backend.clear_session()\n",
    "pre_trained.trainable = True\n",
    "for layer in pre_trained.layers[:-64]:\n",
    "    layer.trainable = False\n",
    "# pre_trained.summary()\n",
    "tfinput = Input(shape=(image_size,image_size,3) )\n",
    "data_augment = data_augmentation(tfinput)\n",
    "pre_process = preprocessing(data_augment)\n",
    "# pre_process = preprocessing(tfinput)\n",
    "inceptionv3_model=pre_trained(pre_process,training=False)\n",
    "flatten = GlobalAveragePooling2D()(inceptionv3_model)\n",
    "# flatten = Flatten()(inceptionv3_model)\n",
    "# Dense1 = Dense(255, activation=\"relu\")(flatten)\n",
    "# DO1 = Dropout(0.8)(Dense1)\n",
    "# Dense2 = Dense(127, activation=\"relu\")(DO1)\n",
    "# DO2 = Dropout(0.8)(Dense2)\n",
    "\n",
    "DO1 = Dropout(0.8)(flatten)\n",
    "Dense1 = Dense(127,activation = 'relu')(DO1)\n",
    "# DO2 = Dropout(1)(Dense1)\n",
    "\n",
    "DO2 = Dropout(0.8)(Dense1)\n",
    "output = Dense(1, activation=\"sigmoid\")(DO2)\n",
    "model = Model(tfinput,output)\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earlystop = tf.keras.callbacks.EarlyStopping( monitor='val_accuracy',\n",
    "#                                               patience=20,\n",
    "#                                               start_from_epoch = 0,\n",
    "#                                               # baseline = 0.7,\n",
    "#                                               # restore_best_weights = True,\n",
    "#                                               verbose = 1\n",
    "#                                               )\n",
    "total_epochs = history_inceptionv3_init.epoch[-1]+1+ 30\n",
    "history_inceptionv3_ft = model.fit(train_ds\n",
    "                    ,epochs=total_epochs\n",
    "                    ,validation_data=val_ds\n",
    "                    ,initial_epoch=history_inceptionv3_init.epoch[-1]+1\n",
    "                    # ,callbacks = Earlystop\n",
    "                    )\n",
    "model.save(save_dir + \"Inceptionv3_TL_FT\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Other Tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "preprocessing = tf.keras.applications.inception_v3.preprocess_input\n",
    "pre_trained = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size,image_size,3))\n",
    "# Freeze all the layers except the last 2 layers\n",
    "for layer in pre_trained.layers[:-64]:\n",
    "    layer.trainable = False\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal_and_vertical'),\n",
    "  tf.keras.layers.RandomRotation((0,0.3),fill_mode=\"constant\"),\n",
    "  tf.keras.layers.RandomZoom(height_factor=(-0.5,0.5),width_factor=(-0.5,0.5),fill_mode=\"constant\"),\n",
    "  tf.keras.layers.RandomTranslation(height_factor=(-0.25,0.25),width_factor=(-0.25,0.25),fill_mode=\"constant\")\n",
    "  ])\n",
    "\n",
    "tfinput = Input(shape=(image_size,image_size,3) )\n",
    "data_augment = data_augmentation(tfinput)\n",
    "pre_process = preprocessing(data_augment)\n",
    "inceptionv3_model=pre_trained(pre_process,training=True)\n",
    "flatten = Flatten()(inceptionv3_model)\n",
    "Dense1 = Dense(255, activation=\"relu\")(flatten)\n",
    "DO1 = Dropout(0.8)(Dense1)\n",
    "Dense2 = Dense(127, activation=\"relu\")(DO1)\n",
    "DO2 = Dropout(0.8)(Dense2)\n",
    "output = Dense(1, activation=\"sigmoid\")(DO2)\n",
    "model = Model(tfinput,output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "total_epochs = 100\n",
    "history = model.fit(train_ds_aug,\n",
    "                    epochs=total_epochs,\n",
    "                    validation_data=val_ds,\n",
    "                    callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfinput = Input(shape=(image_size,image_size,3) )\n",
    "print(tfinput)\n",
    "# x = data_augmentation(tfinput)\n",
    "x = preprocessing(tfinput)\n",
    "# print(x)\n",
    "x=pre_trained(x,training=True)\n",
    "# print(x)\n",
    "x = Flatten()(x)\n",
    "print(x)\n",
    "x = Dense(255, activation=\"relu\")(x)\n",
    "x = Dropout(0.8)(x)\n",
    "x = Dense(127, activation=\"relu\")(x)\n",
    "x = Dropout(0.8)(x)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(tfinput,output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate = 1e-6),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds\n",
    "                    ,epochs=10\n",
    "                    ,validation_data=val_ds\n",
    "                    # ,callbacks = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs =  history.epoch[-1] + fine_tune_epochs\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=val_ds)\n",
    "\n",
    "Accuracy = history_fine.history['val_loss']\n",
    "plt.plot(Accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 100\n",
    "total_epochs =  history.epoch[-1] + fine_tune_epochs\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=val_ds)\n",
    "\n",
    "Accuracy = history_fine.history['val_accuracy']\n",
    "plt.plot(Accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/home/jj/FYP/Pass_test/mini-DDSM_Inceptionv3_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "preprocessing = tf.keras.applications.vgg16.preprocess_input\n",
    "pre_trained = VGG16(weights='imagenet', include_top=False, input_shape=(image_size,image_size,3))\n",
    "# Freeze all the layers except the last 2 layers\n",
    "for layer in pre_trained.layers[:-12]:\n",
    "    layer.trainable = False\n",
    "tfinput = Input(shape=(image_size,image_size,3) )\n",
    "print(tfinput)\n",
    "# x = data_augmentation(tfinput)\n",
    "x = preprocessing(tfinput)\n",
    "# print(x)\n",
    "x=pre_trained(x,training=True)\n",
    "# print(x)\n",
    "x = Flatten()(x)\n",
    "print(x)\n",
    "x = Dense(255, activation=\"relu\")(x)\n",
    "x = Dropout(0.8)(x)\n",
    "x = Dense(127, activation=\"relu\")(x)\n",
    "x = Dropout(0.8)(x)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(tfinput,output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate = 1e-6),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "epochs_per_cycle = 10\n",
    "init_epoch = 1\n",
    "total_epochs = 10\n",
    "for i in range(10):\n",
    "    train_ds_aug = prepare(train_ds, shuffle=True, augment=True)\n",
    "    history = model.fit(train_ds,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=init_epoch,\n",
    "                         validation_data=val_ds)\n",
    "    init_epoch = init_epoch + epochs_per_cycle\n",
    "    total_epochs = total_epochs + epochs_per_cycle\n",
    "\n",
    "model.save(\"/home/jj/FYP/Pass_test/mini-DDSM_VGG16_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "preprocessing = tf.keras.applications.resnet50.preprocess_input\n",
    "pre_trained = tf.keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(image_size,image_size,3))\n",
    "# Freeze all the layers except the last 2 layers\n",
    "for layer in pre_trained.layers[:-22]:\n",
    "    layer.trainable = False\n",
    "tfinput = Input(shape=(image_size,image_size,3) )\n",
    "print(tfinput)\n",
    "# x = data_augmentation(tfinput)\n",
    "x = preprocessing(tfinput)\n",
    "# print(x)\n",
    "x=pre_trained(x,training=True)\n",
    "# print(x)\n",
    "x = Flatten()(x)\n",
    "print(x)\n",
    "x = Dense(255, activation=\"relu\")(x)\n",
    "x = Dropout(0.8)(x)\n",
    "x = Dense(127, activation=\"relu\")(x)\n",
    "x = Dropout(0.8)(x)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(tfinput,output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "epochs_per_cycle = 10\n",
    "init_epoch = 0\n",
    "total_epochs = 10\n",
    "for i in range(10):\n",
    "    train_ds_aug = prepare(train_ds, shuffle=True, augment=True)\n",
    "    history = model.fit(train_ds,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=init_epoch,\n",
    "                         validation_data=val_ds)\n",
    "    init_epoch = init_epoch + epochs_per_cycle\n",
    "    total_epochs = total_epochs + epochs_per_cycle\n",
    "\n",
    "model.save(\"/home/jj/FYP/Pass_test/mini-DDSM_resnet50_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "preprocessing = tf.keras.applications.inception_v3.preprocess_input\n",
    "pre_trained = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size,image_size,3))\n",
    "# Freeze all the layers except the last 2 layers\n",
    "for layer in pre_trained.layers[:-64]:\n",
    "    layer.trainable = False\n",
    "tfinput = Input(shape=(image_size,image_size,3) )\n",
    "print(tfinput)\n",
    "# x = data_augmentation(tfinput)\n",
    "x = preprocessing(tfinput)\n",
    "# print(x)\n",
    "x=pre_trained(x,training=True)\n",
    "# print(x)\n",
    "x = Flatten()(x)\n",
    "print(x)\n",
    "x = Dense(255, activation=\"relu\")(x)\n",
    "x = Dropout(0.8)(x)\n",
    "x = Dense(127, activation=\"relu\")(x)\n",
    "x = Dropout(0.8)(x)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(tfinput,output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "epochs_per_cycle = 10\n",
    "init_epoch = 0\n",
    "total_epochs = 10\n",
    "for i in range(10):\n",
    "    train_ds_aug = prepare(train_ds, shuffle=True, augment=True)\n",
    "    history = model.fit(train_ds,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=init_epoch,\n",
    "                         validation_data=val_ds)\n",
    "    init_epoch = init_epoch + epochs_per_cycle\n",
    "    total_epochs = total_epochs + epochs_per_cycle\n",
    "\n",
    "model.save(\"/home/jj/FYP/Pass_test/mini-DDSM_inceptionv3_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "preprocessing = tf.keras.applications.efficientnet_v2.preprocess_input\n",
    "pre_trained = tf.keras.applications.efficientnet_v2.EfficientNetV2S(weights='imagenet', include_top=False, input_shape=(image_size,image_size,3))\n",
    "# Freeze all the layers except the last 2 layers\n",
    "for layer in pre_trained.layers[:-75]:\n",
    "    layer.trainable = False\n",
    "tfinput = Input(shape=(image_size,image_size,3) )\n",
    "print(tfinput)\n",
    "# x = data_augmentation(tfinput)\n",
    "x = preprocessing(tfinput)\n",
    "# print(x)\n",
    "x=pre_trained(x,training=True)\n",
    "# print(x)\n",
    "x = Flatten()(x)\n",
    "print(x)\n",
    "x = Dense(255, activation=\"relu\")(x)\n",
    "x = Dropout(0.8)(x)\n",
    "x = Dense(127, activation=\"relu\")(x)\n",
    "x = Dropout(0.8)(x)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(tfinput,output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "epochs_per_cycle = 10\n",
    "init_epoch = 0\n",
    "total_epochs = 10\n",
    "for i in range(10):\n",
    "    train_ds_aug = prepare(train_ds, shuffle=True, augment=True)\n",
    "    history = model.fit(train_ds,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=init_epoch,\n",
    "                         validation_data=val_ds)\n",
    "    init_epoch = init_epoch + epochs_per_cycle\n",
    "    total_epochs = total_epochs + epochs_per_cycle\n",
    "\n",
    "model.save(\"/home/jj/FYP/Pass_test/mini-DDSM_efficientnet_v2_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained = tf.keras.applications.efficientnet_v2.EfficientNetV2S(weights='imagenet', include_top=False, input_shape=(image_size,image_size,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsl_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "536095fdb6bd2f165a1201bb0062de5a189a09ebe7161d2185db54f5809b867b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
